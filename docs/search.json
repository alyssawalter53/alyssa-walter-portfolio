[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Alyssa Walter and I am a senior majoring in Marine Science and minoring in Statistics at CSU Monterey Bay. I am currently serving as the AS College of Science Senator, and am a NOAA Hollings, Sally Casanova, and UROC Scholar. My research focuses on elasmobranch movement ecology and reproduction, with an emphasis on enhancing our understanding of the ocean’s top predators to support conservation efforts for species of ecological and economic importance. I am looking forward to using the skills, networks, and experience I have gained during my time as an undergraduate to aid in my pursuit of a PhD in Marine Ecology and Fisheries Management."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alyssa Walter",
    "section": "",
    "text": "Alyssa Walter is a senior at California State University, Monterey Bay."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Alyssa Walter",
    "section": "Education",
    "text": "Education\nCalifornia State University, Monterey Bay | Seaside, CA\nB.S. in Marine Science\nMinor in Statistics"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Alyssa Walter",
    "section": "Experience",
    "text": "Experience\nCalifornia State University Monterey Bay | Undergraduate Researcher | November 2022-Present\nChannel Islands National Marine Sanctuary | NOAA Hollings Research Intern | May 2024-August 2024\nChannel Islands National Marine Sanctuary | CSU Council on Ocean Affairs, Science & Technology Research Intern | June 2023-August 2023\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "page_2_portfolio.html",
    "href": "page_2_portfolio.html",
    "title": "Project Process",
    "section": "",
    "text": "Data Description\nIdentify your data source.\nMy data comes from the NOAA Fisheries Commercial Landings Database, which tracks reported commercial landings of fishes. I utilized their website to select data for 12 large pelagic shark species landed across the U.S.\nhttps://www.fisheries.noaa.gov/foss/f?p=215:200:1455472432287:::::\nDescribe your data, including variables and data types.\nMy data contains commercial fisheries landings from 1915 to 2023, and provides insight into trends in shark landings by state. The dataset includes the following variables: - Year, year of the recorded landings. -State, U.S. state - NMFS Name, National Marine Fisheries Service common name of each species - Pounds and Metric Tons, weight of sharks landed - Dollars, market value of the landed sharks - Confidentiality, whether or not the data is confidential - Collection, whether it was commercially or recreational caught - Scientific Name, scientific name of each species - Tsn, Taxonomic Serial Numbers are a numeric code for the species - Source,original source of the data\nIdentify the research questions you want to answer.\n\nWhich shark species have the highest commercial landing weights (weight of all sharks cought) over time?\nHow do the prominent species landed vary by state?\nAre there trends in the value of shark landings (in dollars) over time, for the shark species that can legally be kept and sold??\nWhat data source (fisheries management organization) had the highest average shark landings in the last 5 years?\n\n\n\nData Visualization\nWhat do you want your final visualizations to look like?\nI want my final visualizations to clearly display trends in shark landings over time, differences among the US states, and the range of relationships between landing weight and commercial value for each species. I plan to create a line graph showing changes in landings (in pounds or metric tons) for all shark species over time. I will also create a bar chart that compares the total market value of shark landings by state. I will use a scatterplot to examine the relationship between the weight of landings and their dollar value.\nWhat do you want to highlight on your final visualizations in order to answer your research questions? How do you plan to do that?\nI want to highlight the top shark species caught by weight and commercial value. I will use color coding to distinguish species and states and apply faceting to break up graphs by category where needed, inorder to include more varibles on each graph.\nWhat is missing from your data or would need to change in your data to create these visualizations?\nSome aspects of the data may need to be adjusted before I can create these visualizations. I will need to group the data by species, year, and state in order to calculate some summary statistics. I will also need to check whether the State and NMFS Name variables are properly formatted for use as categorical variables.\n\n\nData Cleaning\n\nThe answer to at least three of these questions should be “YES” for the data to meet the necessary standards to demonstrate your cleaning.\n\nDo you need to reformat any variables into different types (e.g., factors, time, dates, strings)? Or remove information from variable values?\nYes: I’ll convert Year to a date type, and State, NMFS Name, and Scientific Name into factors for plotting.\nDo you need to deal with any missing data, especially missing data coded other than NA?\nYes: There will be many blank cells in the value column, because some of these species are illegal to keep, and therefore have no true market value.\nDo you need to filter your data? How?\nYes: I will filter out uneccessary cells such as collection and tsn.\nDo you need to create any new variables? What variables? How?\nYes: I may create a variable for “Region” by grouping States together.\nDo you need to add new data (join) to your data? What data? How?\nNo: I should not have to perform any joins unless I decide to add the regions by joining another dataset.\nAre there any variables you can exclude from your data?\nYes: Variables like Tsn, and Collection are not relevant to my project.\nDo you need to pivot your data in any way? Why? How?\nYes: I may pivot my data to combine species across years or states.\nDo you need to summarize any of the variables? Which ones? How?\nYes: I plan to summarize total landings and total dollar value by species, state, and year using group_by and summarize.\nWhat other aspects of your data need to be “fixed” in order to make your data visualizations?\nI may need to standardize state names and abbreviations, and handle zero values in landings and value.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\n\n      year         state            nmfs_name            pounds         \n Min.   :1950   Length:4513        Length:4513        Length:4513       \n 1st Qu.:1997   Class :character   Class :character   Class :character  \n Median :2009   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2006                                                           \n 3rd Qu.:2016                                                           \n Max.   :2023                                                           \n metric_tons          dollars          confidentiality     collection       \n Length:4513        Length:4513        Length:4513        Length:4513       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n scientific_name         tsn            source         \n Length:4513        Min.   :159888   Length:4513       \n Class :character   1st Qu.:159926   Class :character  \n Mode  :character   Median :160275   Mode  :character  \n                    Mean   :160252                     \n                    3rd Qu.:160424                     \n                    Max.   :160787                     \n\n\n\nI used help from AI (ChatGPT) to create the regions dataframe, and to make sure the tideous process of spelling all state names and regions was done correctly.\n\n\n\nData Visualizations"
  }
]